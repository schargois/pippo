PS C:\Users\sterl\cs4756\final project\robot-learning-final> python .\final\final_subprocesses.py

==== Running mode: ppo ====

2025-05-09 01:47:18.409089: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-09 01:47:19.729016: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.

===== Starting Evaluation Mode: ppo =====
Model is None and not using PNN, will not train across tasks. Unless first task.
Training model...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.27s/it]
evaluating self.num_timesteps=1024, mean_reward=1384.7657470703125=======
evaluating self.num_timesteps=1024, success=0.0=======
model saved on eval reward: 1384.7657470703125
--------------------
C:\Users\sterl\AppData\Roaming\Python\Python39\site-packages\numpy\core\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\sterl\AppData\Roaming\Python\Python39\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.26s/it]
evaluating self.num_timesteps=2048, mean_reward=753.99951171875=======
evaluating self.num_timesteps=2048, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.28s/it]
evaluating self.num_timesteps=3072, mean_reward=462.746337890625=======
evaluating self.num_timesteps=3072, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.29s/it]
evaluating self.num_timesteps=4096, mean_reward=495.022705078125=======
evaluating self.num_timesteps=4096, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.30s/it]
evaluating self.num_timesteps=5120, mean_reward=827.0172119140625=======
evaluating self.num_timesteps=5120, success=0.15=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.52s/it]
evaluating self.num_timesteps=6144, mean_reward=1335.9913330078125=======
evaluating self.num_timesteps=6144, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.63s/it]
evaluating self.num_timesteps=7168, mean_reward=1134.623046875=======
evaluating self.num_timesteps=7168, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=8192, mean_reward=1370.7210693359375=======
evaluating self.num_timesteps=8192, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=9216, mean_reward=1306.712646484375=======
evaluating self.num_timesteps=9216, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=10240, mean_reward=1553.6573486328125=======
evaluating self.num_timesteps=10240, success=0.15=======
model saved on eval reward: 1553.6573486328125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=11264, mean_reward=1721.0634765625=======
evaluating self.num_timesteps=11264, success=0.05=======
model saved on eval reward: 1721.0634765625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:34<00:00,  1.70s/it]
evaluating self.num_timesteps=12288, mean_reward=1950.779052734375=======
evaluating self.num_timesteps=12288, success=0.1=======
model saved on eval reward: 1950.779052734375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=13312, mean_reward=2316.259033203125=======
evaluating self.num_timesteps=13312, success=0.3=======
model saved on eval reward: 2316.259033203125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]
evaluating self.num_timesteps=14336, mean_reward=2635.162841796875=======
evaluating self.num_timesteps=14336, success=0.3=======
model saved on eval reward: 2635.162841796875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=15360, mean_reward=2797.546875=======
evaluating self.num_timesteps=15360, success=0.2=======
model saved on eval reward: 2797.546875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.51s/it]
evaluating self.num_timesteps=16384, mean_reward=2722.83154296875=======
evaluating self.num_timesteps=16384, success=0.15=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=17408, mean_reward=2809.326904296875=======
evaluating self.num_timesteps=17408, success=0.3=======
model saved on eval reward: 2809.326904296875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=18432, mean_reward=2305.8251953125=======
evaluating self.num_timesteps=18432, success=0.35=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=19456, mean_reward=2295.94580078125=======
evaluating self.num_timesteps=19456, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=20480, mean_reward=2639.298828125=======
evaluating self.num_timesteps=20480, success=0.3=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=21504, mean_reward=2753.599609375=======
evaluating self.num_timesteps=21504, success=0.3=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.55s/it]
evaluating self.num_timesteps=22528, mean_reward=2882.493408203125=======
evaluating self.num_timesteps=22528, success=0.35=======
model saved on eval reward: 2882.493408203125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.56s/it]
evaluating self.num_timesteps=23552, mean_reward=2947.72412109375=======
evaluating self.num_timesteps=23552, success=0.35=======
model saved on eval reward: 2947.72412109375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=24576, mean_reward=2667.616943359375=======
evaluating self.num_timesteps=24576, success=0.6=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=25600, mean_reward=2744.66357421875=======
evaluating self.num_timesteps=25600, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=26624, mean_reward=2748.22314453125=======
evaluating self.num_timesteps=26624, success=0.45=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=27648, mean_reward=2945.494384765625=======
evaluating self.num_timesteps=27648, success=0.3=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=28672, mean_reward=3435.6796875=======
evaluating self.num_timesteps=28672, success=0.25=======
model saved on eval reward: 3435.6796875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=29696, mean_reward=3386.462890625=======
evaluating self.num_timesteps=29696, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=30720, mean_reward=3137.13623046875=======
evaluating self.num_timesteps=30720, success=0.1=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=31744, mean_reward=2939.339111328125=======
evaluating self.num_timesteps=31744, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=32768, mean_reward=2903.455322265625=======
evaluating self.num_timesteps=32768, success=0.1=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=33792, mean_reward=3101.06787109375=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=34816, mean_reward=3105.36279296875=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=35840, mean_reward=2845.170166015625=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.65s/it]
evaluating self.num_timesteps=36864, mean_reward=2998.192626953125=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=37888, mean_reward=3315.516845703125=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=38912, mean_reward=3269.66943359375=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=39936, mean_reward=3339.935546875=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=40960, mean_reward=3731.27685546875=======
evaluating self.num_timesteps=40960, success=0.0=======
model saved on eval reward: 3731.27685546875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]
evaluating self.num_timesteps=41984, mean_reward=3438.30029296875=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=43008, mean_reward=3386.70458984375=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=44032, mean_reward=3804.20751953125=======
evaluating self.num_timesteps=44032, success=0.0=======
model saved on eval reward: 3804.20751953125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=45056, mean_reward=3896.744873046875=======
evaluating self.num_timesteps=45056, success=0.0=======
model saved on eval reward: 3896.744873046875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.55s/it]
evaluating self.num_timesteps=46080, mean_reward=3612.69775390625=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=47104, mean_reward=3481.723388671875=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]
evaluating self.num_timesteps=48128, mean_reward=4006.33251953125=======
evaluating self.num_timesteps=48128, success=0.0=======
model saved on eval reward: 4006.33251953125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=49152, mean_reward=3953.46044921875=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=50176, mean_reward=4340.5458984375=======
evaluating self.num_timesteps=50176, success=0.0=======
model saved on eval reward: 4340.5458984375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=51200, mean_reward=4330.2734375=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.65s/it]
evaluating self.num_timesteps=52224, mean_reward=4347.24169921875=======
evaluating self.num_timesteps=52224, success=0.0=======
model saved on eval reward: 4347.24169921875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.51s/it]
evaluating self.num_timesteps=53248, mean_reward=4354.9931640625=======
evaluating self.num_timesteps=53248, success=0.0=======
model saved on eval reward: 4354.9931640625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=54272, mean_reward=4423.7041015625=======
evaluating self.num_timesteps=54272, success=0.0=======
model saved on eval reward: 4423.7041015625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=55296, mean_reward=4343.8232421875=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=56320, mean_reward=4601.4404296875=======
evaluating self.num_timesteps=56320, success=0.0=======
model saved on eval reward: 4601.4404296875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=57344, mean_reward=4459.8779296875=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.62s/it]
evaluating self.num_timesteps=58368, mean_reward=4432.0810546875=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=59392, mean_reward=4496.32861328125=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=60416, mean_reward=4568.07421875=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.63s/it]
evaluating self.num_timesteps=61440, mean_reward=4454.61474609375=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=62464, mean_reward=4483.6181640625=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=63488, mean_reward=4380.5068359375=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=64512, mean_reward=4459.00048828125=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.58s/it]
evaluating self.num_timesteps=65536, mean_reward=4564.0751953125=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=66560, mean_reward=4585.15625=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=67584, mean_reward=4620.5810546875=======
evaluating self.num_timesteps=67584, success=0.0=======
model saved on eval reward: 4620.5810546875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.53s/it]
evaluating self.num_timesteps=68608, mean_reward=4568.1005859375=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.57s/it]
evaluating self.num_timesteps=69632, mean_reward=4666.6318359375=======
evaluating self.num_timesteps=69632, success=0.0=======
model saved on eval reward: 4666.6318359375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=70656, mean_reward=4688.4775390625=======
evaluating self.num_timesteps=70656, success=0.0=======
model saved on eval reward: 4688.4775390625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.65s/it]
evaluating self.num_timesteps=71680, mean_reward=4636.111328125=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=72704, mean_reward=4687.3486328125=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=73728, mean_reward=4653.6025390625=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]
evaluating self.num_timesteps=74752, mean_reward=4548.1884765625=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.54s/it]
evaluating self.num_timesteps=75776, mean_reward=4563.7548828125=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=76800, mean_reward=4536.6005859375=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.64s/it]
evaluating self.num_timesteps=77824, mean_reward=4561.0634765625=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=78848, mean_reward=4541.30615234375=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]
evaluating self.num_timesteps=79872, mean_reward=4659.0361328125=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=80896, mean_reward=4436.3671875=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=81920, mean_reward=4539.81494140625=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=82944, mean_reward=4515.123046875=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=83968, mean_reward=4436.97607421875=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=84992, mean_reward=4669.6689453125=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=86016, mean_reward=4477.50439453125=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.65s/it]
evaluating self.num_timesteps=87040, mean_reward=4427.45751953125=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=88064, mean_reward=4624.4775390625=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.57s/it]
evaluating self.num_timesteps=89088, mean_reward=4569.65283203125=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=90112, mean_reward=4469.267578125=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=91136, mean_reward=4450.01953125=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=92160, mean_reward=4541.2021484375=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.52s/it]
evaluating self.num_timesteps=93184, mean_reward=4548.32763671875=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=94208, mean_reward=4643.279296875=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=95232, mean_reward=4631.47509765625=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=96256, mean_reward=4556.80810546875=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.65s/it]
evaluating self.num_timesteps=97280, mean_reward=4556.7548828125=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.64s/it]
evaluating self.num_timesteps=98304, mean_reward=4609.76025390625=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=99328, mean_reward=4474.888671875=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.61s/it]
evaluating self.num_timesteps=100352, mean_reward=4612.47412109375=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=101376, mean_reward=4555.48486328125=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=102400, mean_reward=4725.5146484375=======
evaluating self.num_timesteps=102400, success=0.0=======
model saved on eval reward: 4725.5146484375
--------------------
model saved on eval reward: 4725.5146484375
Evaluating model on reach-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:46<00:00,  1.66s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:39<00:00,  1.60s/it]
ppo Reach - Success: 0.0, Reward: 4721.69873046875
Training model...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=1024, mean_reward=4.741940498352051=======
evaluating self.num_timesteps=1024, success=0.0=======
model saved on eval reward: 4.741940498352051
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.62s/it]
evaluating self.num_timesteps=2048, mean_reward=4.603733539581299=======
evaluating self.num_timesteps=2048, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=3072, mean_reward=4.55807638168335=======
evaluating self.num_timesteps=3072, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.62s/it]
evaluating self.num_timesteps=4096, mean_reward=4.56178092956543=======
evaluating self.num_timesteps=4096, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=5120, mean_reward=4.34765625=======
evaluating self.num_timesteps=5120, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=6144, mean_reward=4.3614373207092285=======
evaluating self.num_timesteps=6144, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=7168, mean_reward=4.515834331512451=======
evaluating self.num_timesteps=7168, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=8192, mean_reward=4.827969074249268=======
evaluating self.num_timesteps=8192, success=0.0=======
model saved on eval reward: 4.827969074249268
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=9216, mean_reward=4.447338581085205=======
evaluating self.num_timesteps=9216, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=10240, mean_reward=4.526193141937256=======
evaluating self.num_timesteps=10240, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=11264, mean_reward=4.328469276428223=======
evaluating self.num_timesteps=11264, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.62s/it]
evaluating self.num_timesteps=12288, mean_reward=4.758747577667236=======
evaluating self.num_timesteps=12288, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=13312, mean_reward=4.652299880981445=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=14336, mean_reward=4.634703159332275=======
evaluating self.num_timesteps=14336, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=15360, mean_reward=4.727153301239014=======
evaluating self.num_timesteps=15360, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=16384, mean_reward=4.574275970458984=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=17408, mean_reward=4.558775424957275=======
evaluating self.num_timesteps=17408, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=18432, mean_reward=4.466905117034912=======
evaluating self.num_timesteps=18432, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=19456, mean_reward=4.411124229431152=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=20480, mean_reward=4.466133117675781=======
evaluating self.num_timesteps=20480, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=21504, mean_reward=4.533466339111328=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=22528, mean_reward=4.601109981536865=======
evaluating self.num_timesteps=22528, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=23552, mean_reward=4.44918155670166=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=24576, mean_reward=4.652831077575684=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=25600, mean_reward=4.4769673347473145=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=26624, mean_reward=4.598924160003662=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:34<00:00,  1.75s/it]
evaluating self.num_timesteps=27648, mean_reward=4.597611904144287=======
evaluating self.num_timesteps=27648, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=28672, mean_reward=4.567870140075684=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=29696, mean_reward=4.673016548156738=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.61s/it]
evaluating self.num_timesteps=30720, mean_reward=4.508286476135254=======
evaluating self.num_timesteps=30720, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=31744, mean_reward=4.483218193054199=======
evaluating self.num_timesteps=31744, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:34<00:00,  1.72s/it]
evaluating self.num_timesteps=32768, mean_reward=4.424396991729736=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=33792, mean_reward=4.6262383460998535=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=34816, mean_reward=4.265469551086426=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=35840, mean_reward=4.621979713439941=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=36864, mean_reward=4.541247844696045=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=37888, mean_reward=4.476201057434082=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=38912, mean_reward=4.4523820877075195=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=39936, mean_reward=4.4936017990112305=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=40960, mean_reward=4.491937637329102=======
evaluating self.num_timesteps=40960, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=41984, mean_reward=4.676591396331787=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=43008, mean_reward=4.709934711456299=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=44032, mean_reward=4.6377787590026855=======
evaluating self.num_timesteps=44032, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=45056, mean_reward=4.650915145874023=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=46080, mean_reward=4.629622459411621=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=47104, mean_reward=4.563596248626709=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=48128, mean_reward=4.8129072189331055=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=49152, mean_reward=4.698392868041992=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:34<00:00,  1.72s/it]
evaluating self.num_timesteps=50176, mean_reward=4.5214524269104=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=51200, mean_reward=4.62515926361084=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=52224, mean_reward=4.280927658081055=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=53248, mean_reward=4.590479850769043=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.68s/it]
evaluating self.num_timesteps=54272, mean_reward=4.769948959350586=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.60s/it]
evaluating self.num_timesteps=55296, mean_reward=4.452385425567627=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=56320, mean_reward=4.27714729309082=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.63s/it]
evaluating self.num_timesteps=57344, mean_reward=4.4331583976745605=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=58368, mean_reward=4.314682960510254=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=59392, mean_reward=4.139233589172363=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=60416, mean_reward=4.5239434242248535=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=61440, mean_reward=4.309964179992676=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=62464, mean_reward=4.496246337890625=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=63488, mean_reward=3.999277114868164=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=64512, mean_reward=4.386005878448486=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=65536, mean_reward=4.24149227142334=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:34<00:00,  1.75s/it]
evaluating self.num_timesteps=66560, mean_reward=4.29335880279541=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.75s/it]
evaluating self.num_timesteps=67584, mean_reward=4.124266147613525=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=68608, mean_reward=4.206737995147705=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=69632, mean_reward=4.148980617523193=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=70656, mean_reward=3.9236629009246826=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=71680, mean_reward=3.820660352706909=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=72704, mean_reward=4.437775611877441=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=73728, mean_reward=3.976519823074341=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=74752, mean_reward=4.600549221038818=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=75776, mean_reward=4.150794506072998=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=76800, mean_reward=4.305941581726074=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=77824, mean_reward=4.422337055206299=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=78848, mean_reward=4.062637805938721=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=79872, mean_reward=4.0962724685668945=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=80896, mean_reward=4.205347537994385=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=81920, mean_reward=4.225930690765381=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=82944, mean_reward=4.209136009216309=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.62s/it]
evaluating self.num_timesteps=83968, mean_reward=3.830256938934326=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=84992, mean_reward=3.86163592338562=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=86016, mean_reward=4.215760707855225=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=87040, mean_reward=4.432859420776367=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=88064, mean_reward=3.9083449840545654=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=89088, mean_reward=4.118406295776367=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=90112, mean_reward=3.863239288330078=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=91136, mean_reward=3.6954779624938965=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.75s/it]
evaluating self.num_timesteps=92160, mean_reward=4.242284297943115=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=93184, mean_reward=4.246831893920898=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=94208, mean_reward=4.0619425773620605=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.64s/it]
evaluating self.num_timesteps=95232, mean_reward=3.6987144947052=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=96256, mean_reward=4.167481422424316=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=97280, mean_reward=3.931121349334717=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=98304, mean_reward=3.570436477661133=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=99328, mean_reward=4.2144951820373535=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.75s/it]
evaluating self.num_timesteps=100352, mean_reward=3.605747699737549=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=101376, mean_reward=4.237559795379639=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.70s/it]
evaluating self.num_timesteps=102400, mean_reward=4.229159832000732=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 4.827969074249268
Evaluating model on pick-place-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:58<00:00,  1.78s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:52<00:00,  1.72s/it]
ppo Pick Place - Success: 0.0, Reward: 4.2102885246276855
Evaluating on previous task: Reach (After Pick Place)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:47<00:00,  1.67s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:42<00:00,  1.63s/it]
ppo Reach (After Pick Place) - Success: 0.0, Reward: 4763.14892578125
Training model...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=1024, mean_reward=292.35418701171875=======
evaluating self.num_timesteps=1024, success=0.0=======
model saved on eval reward: 292.35418701171875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=2048, mean_reward=160.5979461669922=======
evaluating self.num_timesteps=2048, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.70s/it]
evaluating self.num_timesteps=3072, mean_reward=305.56365966796875=======
evaluating self.num_timesteps=3072, success=0.0=======
model saved on eval reward: 305.56365966796875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=4096, mean_reward=274.3786315917969=======
evaluating self.num_timesteps=4096, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=5120, mean_reward=386.5223693847656=======
evaluating self.num_timesteps=5120, success=0.0=======
model saved on eval reward: 386.5223693847656
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=6144, mean_reward=320.34918212890625=======
evaluating self.num_timesteps=6144, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]
evaluating self.num_timesteps=7168, mean_reward=232.12216186523438=======
evaluating self.num_timesteps=7168, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=8192, mean_reward=232.6625518798828=======
evaluating self.num_timesteps=8192, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=9216, mean_reward=185.85986328125=======
evaluating self.num_timesteps=9216, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=10240, mean_reward=402.2951354980469=======
evaluating self.num_timesteps=10240, success=0.0=======
model saved on eval reward: 402.2951354980469
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=11264, mean_reward=459.2190856933594=======
evaluating self.num_timesteps=11264, success=0.0=======
model saved on eval reward: 459.2190856933594
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=12288, mean_reward=356.71661376953125=======
evaluating self.num_timesteps=12288, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=13312, mean_reward=425.318603515625=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=14336, mean_reward=434.27447509765625=======
evaluating self.num_timesteps=14336, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=15360, mean_reward=461.6385192871094=======
evaluating self.num_timesteps=15360, success=0.0=======
model saved on eval reward: 461.6385192871094
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=16384, mean_reward=436.4527893066406=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=17408, mean_reward=464.59222412109375=======
evaluating self.num_timesteps=17408, success=0.0=======
model saved on eval reward: 464.59222412109375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=18432, mean_reward=482.2396545410156=======
evaluating self.num_timesteps=18432, success=0.0=======
model saved on eval reward: 482.2396545410156
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=19456, mean_reward=461.21197509765625=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=20480, mean_reward=470.5439453125=======
evaluating self.num_timesteps=20480, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=21504, mean_reward=469.49200439453125=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=22528, mean_reward=486.02520751953125=======
evaluating self.num_timesteps=22528, success=0.0=======
model saved on eval reward: 486.02520751953125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=23552, mean_reward=463.1807556152344=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=24576, mean_reward=471.30645751953125=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=25600, mean_reward=472.65484619140625=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=26624, mean_reward=479.201171875=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=27648, mean_reward=466.43389892578125=======
evaluating self.num_timesteps=27648, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=28672, mean_reward=462.73394775390625=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=29696, mean_reward=457.623291015625=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=30720, mean_reward=419.86737060546875=======
evaluating self.num_timesteps=30720, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=31744, mean_reward=417.9588928222656=======
evaluating self.num_timesteps=31744, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=32768, mean_reward=420.6944274902344=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=33792, mean_reward=378.694091796875=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=34816, mean_reward=407.667724609375=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=35840, mean_reward=391.85430908203125=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=36864, mean_reward=372.57989501953125=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=37888, mean_reward=379.5093994140625=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=38912, mean_reward=399.821533203125=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=39936, mean_reward=444.2047424316406=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=40960, mean_reward=328.26580810546875=======
evaluating self.num_timesteps=40960, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=41984, mean_reward=300.2131652832031=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=43008, mean_reward=359.55242919921875=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=44032, mean_reward=502.085693359375=======
evaluating self.num_timesteps=44032, success=0.0=======
model saved on eval reward: 502.085693359375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=45056, mean_reward=371.21368408203125=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=46080, mean_reward=289.71990966796875=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=47104, mean_reward=428.0428771972656=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=48128, mean_reward=383.8663635253906=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]
evaluating self.num_timesteps=49152, mean_reward=432.6368103027344=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=50176, mean_reward=444.34130859375=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=51200, mean_reward=396.06781005859375=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=52224, mean_reward=402.939453125=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=53248, mean_reward=428.63592529296875=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=54272, mean_reward=384.55072021484375=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=55296, mean_reward=371.9860534667969=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=56320, mean_reward=367.4327392578125=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.61s/it]
evaluating self.num_timesteps=57344, mean_reward=361.64703369140625=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.64s/it]
evaluating self.num_timesteps=58368, mean_reward=396.25262451171875=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=59392, mean_reward=379.537353515625=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=60416, mean_reward=426.7861328125=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=61440, mean_reward=471.74847412109375=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=62464, mean_reward=402.49456787109375=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=63488, mean_reward=480.744140625=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=64512, mean_reward=458.316650390625=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=65536, mean_reward=479.2674865722656=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=66560, mean_reward=455.8175354003906=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.75s/it]
evaluating self.num_timesteps=67584, mean_reward=471.3460998535156=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=68608, mean_reward=454.66900634765625=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=69632, mean_reward=480.00335693359375=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=70656, mean_reward=439.6458435058594=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=71680, mean_reward=468.25567626953125=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=72704, mean_reward=471.99908447265625=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=73728, mean_reward=470.89630126953125=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.63s/it]
evaluating self.num_timesteps=74752, mean_reward=466.10968017578125=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=75776, mean_reward=479.34942626953125=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.59s/it]
evaluating self.num_timesteps=76800, mean_reward=451.1136169433594=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=77824, mean_reward=480.1692810058594=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=78848, mean_reward=446.428466796875=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=79872, mean_reward=467.17913818359375=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=80896, mean_reward=458.5712890625=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.77s/it]
evaluating self.num_timesteps=81920, mean_reward=433.52227783203125=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=82944, mean_reward=456.69171142578125=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.66s/it]
evaluating self.num_timesteps=83968, mean_reward=472.9249572753906=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.76s/it]
evaluating self.num_timesteps=84992, mean_reward=445.09869384765625=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=86016, mean_reward=464.61767578125=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=87040, mean_reward=475.3307189941406=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=88064, mean_reward=458.3980407714844=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=89088, mean_reward=473.7430725097656=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=90112, mean_reward=468.9115295410156=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=91136, mean_reward=475.7076110839844=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=92160, mean_reward=456.33123779296875=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.59s/it]
evaluating self.num_timesteps=93184, mean_reward=456.74737548828125=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=94208, mean_reward=469.977294921875=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=95232, mean_reward=470.25811767578125=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=96256, mean_reward=479.2535095214844=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=97280, mean_reward=492.55413818359375=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=98304, mean_reward=462.7892150878906=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=99328, mean_reward=473.480712890625=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=100352, mean_reward=457.8003845214844=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=101376, mean_reward=476.26068115234375=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=102400, mean_reward=466.4151306152344=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 502.085693359375
Evaluating model on hammer-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:59<00:00,  1.80s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:53<00:00,  1.73s/it]
ppo Hammer - Success: 0.0, Reward: 461.72198486328125
Evaluating on previous task: Reach (After Hammer)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:45<00:00,  1.66s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:26<00:00,  1.47s/it]
ppo Reach (After Hammer) - Success: 0.0, Reward: 4858.017578125
Evaluating on previous task: Pick Place (After Hammer)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:57<00:00,  1.78s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:49<00:00,  1.69s/it]
ppo Pick Place (After Hammer) - Success: 0.0, Reward: 4.043344020843506

Final evaluation file complete. All combinations have been run.
Results saved to plots/eval_results_2025-05-09_01-47-14.csv

==== Running mode: bc+pnn ====

2025-05-09 08:16:34.393699: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-09 08:16:35.759114: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.

===== Starting Evaluation Mode: bc+pnn =====
Training model...
Collecting expert data for behavior cloning...
  0%|                                                                                                 | 0/10024 [00:00<?, ?it/s]C:\Users\sterl\cs4756\final project\robot-learning-final\final\Metaworld\metaworld\policies\policy.py:49: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]
  warnings.warn(
100%|████████████████████████████████████████████████████████████████████████████████████| 10024/10024 [00:29<00:00, 339.62it/s]
Training actor and critic networks via behavior cloning...
Epoch 1/150 | Actor Loss: 1.05406 | Critic Loss: 0.99446
Epoch 21/150 | Actor Loss: 0.46126 | Critic Loss: 0.93404
Epoch 41/150 | Actor Loss: 0.24451 | Critic Loss: 0.87840
Epoch 61/150 | Actor Loss: 0.13553 | Critic Loss: 0.83031
Epoch 81/150 | Actor Loss: 0.08003 | Critic Loss: 0.77971
Epoch 101/150 | Actor Loss: 0.04561 | Critic Loss: 0.75137
Epoch 121/150 | Actor Loss: 0.02697 | Critic Loss: 0.66203
Epoch 141/150 | Actor Loss: 0.01581 | Critic Loss: 0.61986
Epoch 150/150 | Actor Loss: 0.01249 | Critic Loss: 0.62486
Warm start complete.
Saved plot to plots/warm_start_rew_plot_2025-05-09_01-47-14-bc_pnn-reach-v2.png
Saved plot to plots/warm_start_suc_plot_2025-05-09_01-47-14-bc_pnn-reach-v2.png
Saving model after warm start...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:01<00:00,  1.81s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:48<00:00,  2.08it/s]
Warm Start 2025-05-09_01-47-14-bc_pnn-reach-v2 Total reward: 2842.78662109375
Warm Start 2025-05-09_01-47-14-bc_pnn-reach-v2 Success percentage: 0.8
Evaluating model on reach-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:03<00:00,  1.83s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:36<00:00,  2.71it/s]
bc+pnn Reach - Success: 0.87, Reward: 2883.913818359375
Training model...
Collecting expert data for behavior cloning...
100%|████████████████████████████████████████████████████████████████████████████████████| 10024/10024 [00:32<00:00, 307.02it/s]
Training actor and critic networks via behavior cloning...
Epoch 1/250 | Actor Loss: 1.33849 | Critic Loss: 0.91976
Epoch 21/250 | Actor Loss: 0.50921 | Critic Loss: 0.47450
Epoch 41/250 | Actor Loss: 0.27740 | Critic Loss: 0.43031
Epoch 61/250 | Actor Loss: 0.16289 | Critic Loss: 0.39094
Epoch 81/250 | Actor Loss: 0.09930 | Critic Loss: 0.37878
Epoch 101/250 | Actor Loss: 0.06073 | Critic Loss: 0.37799
Epoch 121/250 | Actor Loss: 0.03821 | Critic Loss: 0.36707
Epoch 141/250 | Actor Loss: 0.02387 | Critic Loss: 0.36123
Epoch 161/250 | Actor Loss: 0.01652 | Critic Loss: 0.36411
Epoch 181/250 | Actor Loss: 0.01175 | Critic Loss: 0.35391
Epoch 201/250 | Actor Loss: 0.00926 | Critic Loss: 0.34919
Epoch 221/250 | Actor Loss: 0.00741 | Critic Loss: 0.35361
Epoch 241/250 | Actor Loss: 0.00583 | Critic Loss: 0.35060
Epoch 250/250 | Actor Loss: 0.00547 | Critic Loss: 0.34871
Warm start complete.
Saved plot to plots/warm_start_rew_plot_2025-05-09_01-47-14-bc_pnn-pick-place-v2.png
Saved plot to plots/warm_start_suc_plot_2025-05-09_01-47-14-bc_pnn-pick-place-v2.png
Saving model after warm start...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:49<00:00,  2.29s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:36<00:00,  2.74it/s]
Warm Start 2025-05-09_01-47-14-bc_pnn-pick-place-v2 Total reward: 140.6848602294922
Warm Start 2025-05-09_01-47-14-bc_pnn-pick-place-v2 Success percentage: 0.93
Evaluating model on pick-place-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:53<00:00,  2.33s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:33<00:00,  3.02it/s]
bc+pnn Pick Place - Success: 0.96, Reward: 71.83609008789062
Evaluating on previous task: Reach (After Pick Place)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:45<00:00,  2.26s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:56<00:00,  1.76it/s]
bc+pnn Reach (After Pick Place) - Success: 0.83, Reward: 1189.6385498046875
Training model...
Collecting expert data for behavior cloning...
100%|████████████████████████████████████████████████████████████████████████████████████| 10024/10024 [00:32<00:00, 313.20it/s]
Training actor and critic networks via behavior cloning...
Epoch 1/350 | Actor Loss: 1.37023 | Critic Loss: 0.94263
Epoch 21/350 | Actor Loss: 0.51944 | Critic Loss: 0.61875
Epoch 41/350 | Actor Loss: 0.29283 | Critic Loss: 0.60392
Epoch 61/350 | Actor Loss: 0.17545 | Critic Loss: 0.58915
Epoch 81/350 | Actor Loss: 0.11344 | Critic Loss: 0.58390
Epoch 101/350 | Actor Loss: 0.07772 | Critic Loss: 0.58408
Epoch 121/350 | Actor Loss: 0.05500 | Critic Loss: 0.58254
Epoch 141/350 | Actor Loss: 0.04048 | Critic Loss: 0.57639
Epoch 161/350 | Actor Loss: 0.03082 | Critic Loss: 0.57303
Epoch 181/350 | Actor Loss: 0.02623 | Critic Loss: 0.59322
WARNING: Nan, Inf or huge value in QACC at DOF 12. The simulation is unstable. Time = 1.6900.

Epoch 201/350 | Actor Loss: 0.02221 | Critic Loss: 0.57535
Epoch 221/350 | Actor Loss: 0.01901 | Critic Loss: 0.57111
WARNING: Nan, Inf or huge value in QACC at DOF 9. The simulation is unstable. Time = 1.7850.

Epoch 241/350 | Actor Loss: 0.01940 | Critic Loss: 0.56869
Epoch 261/350 | Actor Loss: 0.01714 | Critic Loss: 0.57118
Epoch 281/350 | Actor Loss: 0.01494 | Critic Loss: 0.56831
Epoch 301/350 | Actor Loss: 0.01416 | Critic Loss: 0.56373
Epoch 321/350 | Actor Loss: 0.01403 | Critic Loss: 0.56440
Epoch 341/350 | Actor Loss: 0.01812 | Critic Loss: 0.56957
Epoch 350/350 | Actor Loss: 0.01298 | Critic Loss: 0.57292
Warm start complete.
Saved plot to plots/warm_start_rew_plot_2025-05-09_01-47-14-bc_pnn-hammer-v2.png
Saved plot to plots/warm_start_suc_plot_2025-05-09_01-47-14-bc_pnn-hammer-v2.png
Saving model after warm start...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [08:11<00:00,  4.91s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:01<00:00,  1.64it/s]
Warm Start 2025-05-09_01-47-14-bc_pnn-hammer-v2 Total reward: 470.7313232421875
Warm Start 2025-05-09_01-47-14-bc_pnn-hammer-v2 Success percentage: 0.92
Evaluating model on hammer-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:51<00:00,  2.92s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:02<00:00,  1.60it/s]
bc+pnn Hammer - Success: 0.9, Reward: 472.4335021972656
Evaluating on previous task: Reach (After Hammer)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:18<00:00,  3.18s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:38<00:00,  2.78s/it]
bc+pnn Reach (After Hammer) - Success: 0.16, Reward: 484.3785400390625
Evaluating on previous task: Pick Place (After Hammer)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:41<00:00,  2.21s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:38<00:00,  2.79s/it]
bc+pnn Pick Place (After Hammer) - Success: 0.0, Reward: 2.6348776817321777

Final evaluation file complete. All combinations have been run.
Results saved to plots/eval_results_2025-05-09_01-47-14.csv

==== Running mode: ppo+pnn ====

2025-05-09 10:27:37.183728: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-09 10:27:38.172311: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.

===== Starting Evaluation Mode: ppo+pnn =====
Training model...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.93s/it]
evaluating self.num_timesteps=1024, mean_reward=1045.018798828125=======
evaluating self.num_timesteps=1024, success=0.15=======
model saved on eval reward: 1045.018798828125
--------------------
C:\Users\sterl\AppData\Roaming\Python\Python39\site-packages\numpy\core\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\sterl\AppData\Roaming\Python\Python39\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.96s/it]
evaluating self.num_timesteps=2048, mean_reward=1616.5931396484375=======
evaluating self.num_timesteps=2048, success=0.2=======
model saved on eval reward: 1616.5931396484375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.01s/it]
evaluating self.num_timesteps=3072, mean_reward=1590.2608642578125=======
evaluating self.num_timesteps=3072, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.99s/it]
evaluating self.num_timesteps=4096, mean_reward=1577.103271484375=======
evaluating self.num_timesteps=4096, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.99s/it]
evaluating self.num_timesteps=5120, mean_reward=1788.1402587890625=======
evaluating self.num_timesteps=5120, success=0.15=======
model saved on eval reward: 1788.1402587890625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.01s/it]
evaluating self.num_timesteps=6144, mean_reward=1598.5924072265625=======
evaluating self.num_timesteps=6144, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.00s/it]
evaluating self.num_timesteps=7168, mean_reward=2010.121337890625=======
evaluating self.num_timesteps=7168, success=0.05=======
model saved on eval reward: 2010.121337890625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.96s/it]
evaluating self.num_timesteps=8192, mean_reward=1900.7867431640625=======
evaluating self.num_timesteps=8192, success=0.15=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.95s/it]
evaluating self.num_timesteps=9216, mean_reward=1744.7308349609375=======
evaluating self.num_timesteps=9216, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.98s/it]
evaluating self.num_timesteps=10240, mean_reward=1739.695556640625=======
evaluating self.num_timesteps=10240, success=0.15=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.93s/it]
evaluating self.num_timesteps=11264, mean_reward=1950.1839599609375=======
evaluating self.num_timesteps=11264, success=0.1=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.91s/it]
evaluating self.num_timesteps=12288, mean_reward=1760.298583984375=======
evaluating self.num_timesteps=12288, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.28s/it]
evaluating self.num_timesteps=13312, mean_reward=2048.91796875=======
evaluating self.num_timesteps=13312, success=0.1=======
model saved on eval reward: 2048.91796875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.37s/it]
evaluating self.num_timesteps=14336, mean_reward=2355.6484375=======
evaluating self.num_timesteps=14336, success=0.15=======
model saved on eval reward: 2355.6484375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.28s/it]
evaluating self.num_timesteps=15360, mean_reward=1971.593994140625=======
evaluating self.num_timesteps=15360, success=0.1=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]
evaluating self.num_timesteps=16384, mean_reward=2288.85009765625=======
evaluating self.num_timesteps=16384, success=0.15=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.25s/it]
evaluating self.num_timesteps=17408, mean_reward=1811.4556884765625=======
evaluating self.num_timesteps=17408, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]
evaluating self.num_timesteps=18432, mean_reward=2071.509033203125=======
evaluating self.num_timesteps=18432, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.25s/it]
evaluating self.num_timesteps=19456, mean_reward=2516.170654296875=======
evaluating self.num_timesteps=19456, success=0.25=======
model saved on eval reward: 2516.170654296875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:26<00:00,  1.31s/it]
evaluating self.num_timesteps=20480, mean_reward=2459.470703125=======
evaluating self.num_timesteps=20480, success=0.25=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.25s/it]
evaluating self.num_timesteps=21504, mean_reward=2551.74658203125=======
evaluating self.num_timesteps=21504, success=0.1=======
model saved on eval reward: 2551.74658203125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.26s/it]
evaluating self.num_timesteps=22528, mean_reward=2899.950927734375=======
evaluating self.num_timesteps=22528, success=0.0=======
model saved on eval reward: 2899.950927734375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=23552, mean_reward=2686.343505859375=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.22s/it]
evaluating self.num_timesteps=24576, mean_reward=2683.406005859375=======
evaluating self.num_timesteps=24576, success=0.15=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:23<00:00,  1.20s/it]
evaluating self.num_timesteps=25600, mean_reward=2955.999267578125=======
evaluating self.num_timesteps=25600, success=0.1=======
model saved on eval reward: 2955.999267578125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.28s/it]
evaluating self.num_timesteps=26624, mean_reward=2879.24951171875=======
evaluating self.num_timesteps=26624, success=0.3=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.99s/it]
evaluating self.num_timesteps=27648, mean_reward=2947.61767578125=======
evaluating self.num_timesteps=27648, success=0.2=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=28672, mean_reward=3218.171142578125=======
evaluating self.num_timesteps=28672, success=0.15=======
model saved on eval reward: 3218.171142578125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=29696, mean_reward=3301.028564453125=======
evaluating self.num_timesteps=29696, success=0.05=======
model saved on eval reward: 3301.028564453125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=30720, mean_reward=2950.4296875=======
evaluating self.num_timesteps=30720, success=0.1=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.01s/it]
evaluating self.num_timesteps=31744, mean_reward=2959.3740234375=======
evaluating self.num_timesteps=31744, success=0.1=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.15s/it]
evaluating self.num_timesteps=32768, mean_reward=2798.66015625=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.97s/it]
evaluating self.num_timesteps=33792, mean_reward=3218.832275390625=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.96s/it]
evaluating self.num_timesteps=34816, mean_reward=3198.6328125=======
evaluating self.num_timesteps=34816, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.02s/it]
evaluating self.num_timesteps=35840, mean_reward=3280.321533203125=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=36864, mean_reward=3369.44873046875=======
evaluating self.num_timesteps=36864, success=0.0=======
model saved on eval reward: 3369.44873046875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.96s/it]
evaluating self.num_timesteps=37888, mean_reward=3615.68359375=======
evaluating self.num_timesteps=37888, success=0.0=======
model saved on eval reward: 3615.68359375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.04s/it]
evaluating self.num_timesteps=38912, mean_reward=3645.62109375=======
evaluating self.num_timesteps=38912, success=0.0=======
model saved on eval reward: 3645.62109375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.98s/it]
evaluating self.num_timesteps=39936, mean_reward=3797.685546875=======
evaluating self.num_timesteps=39936, success=0.0=======
model saved on eval reward: 3797.685546875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.99s/it]
evaluating self.num_timesteps=40960, mean_reward=3976.84619140625=======
evaluating self.num_timesteps=40960, success=0.0=======
model saved on eval reward: 3976.84619140625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.04s/it]
evaluating self.num_timesteps=41984, mean_reward=3757.876953125=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.03s/it]
evaluating self.num_timesteps=43008, mean_reward=3721.59228515625=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]
evaluating self.num_timesteps=44032, mean_reward=4048.217529296875=======
evaluating self.num_timesteps=44032, success=0.0=======
model saved on eval reward: 4048.217529296875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.22s/it]
evaluating self.num_timesteps=45056, mean_reward=3969.014404296875=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.20s/it]
evaluating self.num_timesteps=46080, mean_reward=3592.310546875=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.21s/it]
evaluating self.num_timesteps=47104, mean_reward=3470.791015625=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.22s/it]
evaluating self.num_timesteps=48128, mean_reward=4014.063232421875=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.21s/it]
evaluating self.num_timesteps=49152, mean_reward=3597.56005859375=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=50176, mean_reward=4108.89111328125=======
evaluating self.num_timesteps=50176, success=0.0=======
model saved on eval reward: 4108.89111328125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=51200, mean_reward=4130.77392578125=======
evaluating self.num_timesteps=51200, success=0.0=======
model saved on eval reward: 4130.77392578125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=52224, mean_reward=4265.59326171875=======
evaluating self.num_timesteps=52224, success=0.0=======
model saved on eval reward: 4265.59326171875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=53248, mean_reward=4265.9697265625=======
evaluating self.num_timesteps=53248, success=0.0=======
model saved on eval reward: 4265.9697265625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=54272, mean_reward=4259.802734375=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=55296, mean_reward=4323.9345703125=======
evaluating self.num_timesteps=55296, success=0.0=======
model saved on eval reward: 4323.9345703125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=56320, mean_reward=4562.7001953125=======
evaluating self.num_timesteps=56320, success=0.0=======
model saved on eval reward: 4562.7001953125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.51s/it]
evaluating self.num_timesteps=57344, mean_reward=4529.87939453125=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:23<00:00,  1.19s/it]
evaluating self.num_timesteps=58368, mean_reward=4326.6708984375=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:23<00:00,  1.20s/it]
evaluating self.num_timesteps=59392, mean_reward=4462.7216796875=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.24s/it]
evaluating self.num_timesteps=60416, mean_reward=4401.17626953125=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.23s/it]
evaluating self.num_timesteps=61440, mean_reward=4375.59033203125=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.21s/it]
evaluating self.num_timesteps=62464, mean_reward=4402.16064453125=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.36s/it]
evaluating self.num_timesteps=63488, mean_reward=4296.7177734375=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=64512, mean_reward=4483.10498046875=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=65536, mean_reward=4275.4912109375=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=66560, mean_reward=4389.021484375=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=67584, mean_reward=4311.51708984375=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=68608, mean_reward=4505.6982421875=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=69632, mean_reward=4553.6103515625=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=70656, mean_reward=4426.88037109375=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=71680, mean_reward=4576.83544921875=======
evaluating self.num_timesteps=71680, success=0.0=======
model saved on eval reward: 4576.83544921875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=72704, mean_reward=4565.30126953125=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=73728, mean_reward=4665.97509765625=======
evaluating self.num_timesteps=73728, success=0.0=======
model saved on eval reward: 4665.97509765625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=74752, mean_reward=4533.18896484375=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=75776, mean_reward=4287.072265625=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=76800, mean_reward=4657.5546875=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=77824, mean_reward=4507.9521484375=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=78848, mean_reward=4520.27734375=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=79872, mean_reward=4564.068359375=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=80896, mean_reward=4437.33984375=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=81920, mean_reward=4583.3173828125=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=82944, mean_reward=4634.35791015625=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=83968, mean_reward=4663.7568359375=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=84992, mean_reward=4667.46630859375=======
evaluating self.num_timesteps=84992, success=0.0=======
model saved on eval reward: 4667.46630859375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=86016, mean_reward=4714.99853515625=======
evaluating self.num_timesteps=86016, success=0.0=======
model saved on eval reward: 4714.99853515625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=87040, mean_reward=4632.36376953125=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=88064, mean_reward=4687.9130859375=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=89088, mean_reward=4715.9990234375=======
evaluating self.num_timesteps=89088, success=0.0=======
model saved on eval reward: 4715.9990234375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.37s/it]
evaluating self.num_timesteps=90112, mean_reward=4741.86083984375=======
evaluating self.num_timesteps=90112, success=0.0=======
model saved on eval reward: 4741.86083984375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=91136, mean_reward=4716.3427734375=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=92160, mean_reward=4762.89892578125=======
evaluating self.num_timesteps=92160, success=0.0=======
model saved on eval reward: 4762.89892578125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=93184, mean_reward=4711.40869140625=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=94208, mean_reward=4746.048828125=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=95232, mean_reward=4700.5146484375=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=96256, mean_reward=4696.9755859375=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=97280, mean_reward=4718.22216796875=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=98304, mean_reward=4736.2802734375=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=99328, mean_reward=4675.482421875=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=100352, mean_reward=4728.93994140625=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=101376, mean_reward=4662.1337890625=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=102400, mean_reward=4743.6103515625=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 4762.89892578125
Evaluating model on reach-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:19<00:00,  1.40s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:15<00:00,  1.36s/it]
ppo+pnn Reach - Success: 0.0, Reward: 4728.0107421875
Training model...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=1024, mean_reward=5.55912446975708=======
evaluating self.num_timesteps=1024, success=0.0=======
model saved on eval reward: 5.55912446975708
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=2048, mean_reward=4.781652450561523=======
evaluating self.num_timesteps=2048, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=3072, mean_reward=5.508908271789551=======
evaluating self.num_timesteps=3072, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=4096, mean_reward=4.343444347381592=======
evaluating self.num_timesteps=4096, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=5120, mean_reward=4.702371120452881=======
evaluating self.num_timesteps=5120, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=6144, mean_reward=6.052659511566162=======
evaluating self.num_timesteps=6144, success=0.0=======
model saved on eval reward: 6.052659511566162
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=7168, mean_reward=6.633243560791016=======
evaluating self.num_timesteps=7168, success=0.0=======
model saved on eval reward: 6.633243560791016
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=8192, mean_reward=6.678320407867432=======
evaluating self.num_timesteps=8192, success=0.0=======
model saved on eval reward: 6.678320407867432
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=9216, mean_reward=7.091919898986816=======
evaluating self.num_timesteps=9216, success=0.0=======
model saved on eval reward: 7.091919898986816
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=10240, mean_reward=6.356637001037598=======
evaluating self.num_timesteps=10240, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=11264, mean_reward=5.983258247375488=======
evaluating self.num_timesteps=11264, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=12288, mean_reward=5.393851280212402=======
evaluating self.num_timesteps=12288, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=13312, mean_reward=5.218785285949707=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=14336, mean_reward=5.439205646514893=======
evaluating self.num_timesteps=14336, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=15360, mean_reward=6.143436908721924=======
evaluating self.num_timesteps=15360, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=16384, mean_reward=5.192696571350098=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=17408, mean_reward=5.823351860046387=======
evaluating self.num_timesteps=17408, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=18432, mean_reward=5.916767597198486=======
evaluating self.num_timesteps=18432, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=19456, mean_reward=5.538910388946533=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=20480, mean_reward=5.875967025756836=======
evaluating self.num_timesteps=20480, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=21504, mean_reward=5.903521537780762=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=22528, mean_reward=6.309093952178955=======
evaluating self.num_timesteps=22528, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=23552, mean_reward=6.517556667327881=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=24576, mean_reward=6.932151794433594=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=25600, mean_reward=6.394314289093018=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=26624, mean_reward=5.929403305053711=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:37<00:00,  1.87s/it]
evaluating self.num_timesteps=27648, mean_reward=5.75180721282959=======
evaluating self.num_timesteps=27648, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=28672, mean_reward=5.172275066375732=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=29696, mean_reward=5.646235942840576=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=30720, mean_reward=5.946272850036621=======
evaluating self.num_timesteps=30720, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=31744, mean_reward=6.297882556915283=======
evaluating self.num_timesteps=31744, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=32768, mean_reward=5.835938453674316=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=33792, mean_reward=5.803612232208252=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=34816, mean_reward=6.936528205871582=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=35840, mean_reward=6.324581623077393=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=36864, mean_reward=6.286494731903076=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=37888, mean_reward=5.623343467712402=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=38912, mean_reward=6.072606086730957=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=39936, mean_reward=5.6364054679870605=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=40960, mean_reward=5.31754732131958=======
evaluating self.num_timesteps=40960, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=41984, mean_reward=5.834336757659912=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=43008, mean_reward=5.683013916015625=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=44032, mean_reward=5.925475120544434=======
evaluating self.num_timesteps=44032, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=45056, mean_reward=5.677818298339844=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=46080, mean_reward=6.1168107986450195=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=47104, mean_reward=6.102328300476074=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=48128, mean_reward=6.382434844970703=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=49152, mean_reward=5.92271614074707=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=50176, mean_reward=6.010081768035889=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=51200, mean_reward=6.122950553894043=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=52224, mean_reward=6.082574844360352=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=53248, mean_reward=6.695982933044434=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=54272, mean_reward=6.640107154846191=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=55296, mean_reward=6.350188732147217=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=56320, mean_reward=5.742975234985352=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=57344, mean_reward=5.66079568862915=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=58368, mean_reward=6.089816093444824=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=59392, mean_reward=6.178618907928467=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=60416, mean_reward=6.574383735656738=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:41<00:00,  2.05s/it]
evaluating self.num_timesteps=61440, mean_reward=5.898891448974609=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=62464, mean_reward=6.368510723114014=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=63488, mean_reward=5.892333984375=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=64512, mean_reward=5.98618221282959=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=65536, mean_reward=6.066315174102783=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=66560, mean_reward=6.200182914733887=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=67584, mean_reward=6.467846870422363=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=68608, mean_reward=6.20407247543335=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=69632, mean_reward=6.862454891204834=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=70656, mean_reward=6.553709983825684=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=71680, mean_reward=5.778827667236328=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=72704, mean_reward=6.5271406173706055=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=73728, mean_reward=6.313657760620117=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=74752, mean_reward=6.452827453613281=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=75776, mean_reward=6.747929573059082=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=76800, mean_reward=6.08983039855957=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=77824, mean_reward=6.769022464752197=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=78848, mean_reward=6.245778560638428=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=79872, mean_reward=6.501167297363281=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=80896, mean_reward=6.555994510650635=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=81920, mean_reward=6.802149772644043=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=82944, mean_reward=6.77609395980835=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=83968, mean_reward=6.798631191253662=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=84992, mean_reward=6.622393608093262=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=86016, mean_reward=6.851467132568359=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.85s/it]
evaluating self.num_timesteps=87040, mean_reward=6.575936317443848=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=88064, mean_reward=6.908383369445801=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=89088, mean_reward=6.377258777618408=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=90112, mean_reward=6.918843746185303=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=91136, mean_reward=6.148343086242676=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=92160, mean_reward=6.803927421569824=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=93184, mean_reward=6.257237434387207=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=94208, mean_reward=6.495043754577637=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=95232, mean_reward=6.50064754486084=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=96256, mean_reward=6.533017635345459=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=97280, mean_reward=6.924144744873047=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=98304, mean_reward=6.8032989501953125=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=99328, mean_reward=6.82616662979126=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=100352, mean_reward=6.369955062866211=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=101376, mean_reward=6.566943168640137=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=102400, mean_reward=6.288866996765137=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 7.091919898986816
Evaluating model on pick-place-v2...
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:00<00:00,  1.80s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:54<00:00,  1.75s/it]
ppo+pnn Pick Place - Success: 0.0, Reward: 6.519679069519043
Evaluating on previous task: Reach (After Pick Place)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:51<00:00,  1.71s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:48<00:00,  1.68s/it]
ppo+pnn Reach (After Pick Place) - Success: 0.0, Reward: 256.7926940917969
Training model...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=1024, mean_reward=460.5400390625=======
evaluating self.num_timesteps=1024, success=0.0=======
model saved on eval reward: 460.5400390625
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=2048, mean_reward=480.10247802734375=======
evaluating self.num_timesteps=2048, success=0.0=======
model saved on eval reward: 480.10247802734375
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.14s/it]
evaluating self.num_timesteps=3072, mean_reward=451.81292724609375=======
evaluating self.num_timesteps=3072, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=4096, mean_reward=475.9613342285156=======
evaluating self.num_timesteps=4096, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=5120, mean_reward=456.2007751464844=======
evaluating self.num_timesteps=5120, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=6144, mean_reward=471.82806396484375=======
evaluating self.num_timesteps=6144, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=7168, mean_reward=476.707275390625=======
evaluating self.num_timesteps=7168, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.10s/it]
evaluating self.num_timesteps=8192, mean_reward=488.18487548828125=======
evaluating self.num_timesteps=8192, success=0.0=======
model saved on eval reward: 488.18487548828125
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=9216, mean_reward=472.077880859375=======
evaluating self.num_timesteps=9216, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=10240, mean_reward=485.4134216308594=======
evaluating self.num_timesteps=10240, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=11264, mean_reward=464.2889709472656=======
evaluating self.num_timesteps=11264, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=12288, mean_reward=482.93304443359375=======
evaluating self.num_timesteps=12288, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.15s/it]
evaluating self.num_timesteps=13312, mean_reward=454.02178955078125=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.11s/it]
evaluating self.num_timesteps=14336, mean_reward=464.6355895996094=======
evaluating self.num_timesteps=14336, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.10s/it]
evaluating self.num_timesteps=15360, mean_reward=465.9500427246094=======
evaluating self.num_timesteps=15360, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=16384, mean_reward=441.8336486816406=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.14s/it]
evaluating self.num_timesteps=17408, mean_reward=468.5426330566406=======
evaluating self.num_timesteps=17408, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=18432, mean_reward=486.6219177246094=======
evaluating self.num_timesteps=18432, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=19456, mean_reward=464.9161682128906=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.15s/it]
evaluating self.num_timesteps=20480, mean_reward=474.41912841796875=======
evaluating self.num_timesteps=20480, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.10s/it]
evaluating self.num_timesteps=21504, mean_reward=471.9537658691406=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=22528, mean_reward=488.85125732421875=======
evaluating self.num_timesteps=22528, success=0.0=======
model saved on eval reward: 488.85125732421875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.13s/it]
evaluating self.num_timesteps=23552, mean_reward=466.68316650390625=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.15s/it]
evaluating self.num_timesteps=24576, mean_reward=475.32159423828125=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=25600, mean_reward=476.4208984375=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=26624, mean_reward=483.0005798339844=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.12s/it]
evaluating self.num_timesteps=27648, mean_reward=469.73779296875=======
evaluating self.num_timesteps=27648, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.91s/it]
evaluating self.num_timesteps=28672, mean_reward=465.39593505859375=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:37<00:00,  1.85s/it]
evaluating self.num_timesteps=29696, mean_reward=460.65313720703125=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=30720, mean_reward=470.67474365234375=======
evaluating self.num_timesteps=30720, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.92s/it]
evaluating self.num_timesteps=31744, mean_reward=494.0467834472656=======
evaluating self.num_timesteps=31744, success=0.05=======
model saved on eval reward: 494.0467834472656
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:01<00:00,  3.10s/it]
evaluating self.num_timesteps=32768, mean_reward=474.82952880859375=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.55s/it]
evaluating self.num_timesteps=33792, mean_reward=473.79327392578125=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.44s/it]
evaluating self.num_timesteps=34816, mean_reward=459.78961181640625=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:09<00:00,  3.47s/it]
evaluating self.num_timesteps=35840, mean_reward=468.44683837890625=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=36864, mean_reward=474.5806579589844=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:12<00:00,  3.61s/it]
evaluating self.num_timesteps=37888, mean_reward=478.5986328125=======
evaluating self.num_timesteps=37888, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:01<00:00,  3.09s/it]
evaluating self.num_timesteps=38912, mean_reward=474.08074951171875=======
evaluating self.num_timesteps=38912, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:10<00:00,  3.52s/it]
evaluating self.num_timesteps=39936, mean_reward=473.81103515625=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:12<00:00,  3.65s/it]
evaluating self.num_timesteps=40960, mean_reward=459.83831787109375=======
evaluating self.num_timesteps=40960, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:06<00:00,  3.34s/it]
evaluating self.num_timesteps=41984, mean_reward=472.411865234375=======
evaluating self.num_timesteps=41984, success=0.05=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.59s/it]
evaluating self.num_timesteps=43008, mean_reward=478.80963134765625=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.44s/it]
evaluating self.num_timesteps=44032, mean_reward=505.95770263671875=======
evaluating self.num_timesteps=44032, success=0.05=======
model saved on eval reward: 505.95770263671875
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:12<00:00,  3.60s/it]
evaluating self.num_timesteps=45056, mean_reward=460.25701904296875=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:16<00:00,  3.82s/it]
evaluating self.num_timesteps=46080, mean_reward=456.1556091308594=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.44s/it]
evaluating self.num_timesteps=47104, mean_reward=475.19384765625=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:51<00:00,  2.57s/it]
evaluating self.num_timesteps=48128, mean_reward=461.9165954589844=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.41s/it]
evaluating self.num_timesteps=49152, mean_reward=457.92529296875=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:09<00:00,  3.47s/it]
evaluating self.num_timesteps=50176, mean_reward=447.7672424316406=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:04<00:00,  3.24s/it]
evaluating self.num_timesteps=51200, mean_reward=461.14794921875=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:10<00:00,  3.53s/it]
evaluating self.num_timesteps=52224, mean_reward=476.616943359375=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:09<00:00,  3.48s/it]
evaluating self.num_timesteps=53248, mean_reward=476.0511169433594=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:10<00:00,  3.54s/it]
evaluating self.num_timesteps=54272, mean_reward=453.4862365722656=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.99s/it]
evaluating self.num_timesteps=55296, mean_reward=460.86297607421875=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.58s/it]
evaluating self.num_timesteps=56320, mean_reward=458.89923095703125=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:04<00:00,  3.21s/it]
evaluating self.num_timesteps=57344, mean_reward=454.68988037109375=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:57<00:00,  2.86s/it]
evaluating self.num_timesteps=58368, mean_reward=472.65185546875=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:54<00:00,  2.71s/it]
evaluating self.num_timesteps=59392, mean_reward=454.790283203125=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:56<00:00,  2.82s/it]
evaluating self.num_timesteps=60416, mean_reward=483.55731201171875=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.44s/it]
evaluating self.num_timesteps=61440, mean_reward=476.50811767578125=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.43s/it]
evaluating self.num_timesteps=62464, mean_reward=471.5149841308594=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:09<00:00,  3.46s/it]
evaluating self.num_timesteps=63488, mean_reward=484.3604431152344=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:09<00:00,  3.48s/it]
evaluating self.num_timesteps=64512, mean_reward=462.90252685546875=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:13<00:00,  3.66s/it]
evaluating self.num_timesteps=65536, mean_reward=482.7462463378906=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:52<00:00,  2.63s/it]
evaluating self.num_timesteps=66560, mean_reward=486.19573974609375=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.24s/it]
evaluating self.num_timesteps=67584, mean_reward=479.5694274902344=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:47<00:00,  2.35s/it]
evaluating self.num_timesteps=68608, mean_reward=488.0840759277344=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.32s/it]
evaluating self.num_timesteps=69632, mean_reward=486.8077697753906=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.34s/it]
evaluating self.num_timesteps=70656, mean_reward=426.32855224609375=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.32s/it]
evaluating self.num_timesteps=71680, mean_reward=475.19390869140625=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:51<00:00,  2.56s/it]
evaluating self.num_timesteps=72704, mean_reward=472.14166259765625=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:49<00:00,  2.47s/it]
evaluating self.num_timesteps=73728, mean_reward=466.34686279296875=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:50<00:00,  2.55s/it]
evaluating self.num_timesteps=74752, mean_reward=460.6534118652344=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:48<00:00,  2.44s/it]
evaluating self.num_timesteps=75776, mean_reward=456.0419921875=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.31s/it]
evaluating self.num_timesteps=76800, mean_reward=457.7893981933594=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.23s/it]
evaluating self.num_timesteps=77824, mean_reward=486.310791015625=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.25s/it]
evaluating self.num_timesteps=78848, mean_reward=451.02154541015625=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:51<00:00,  2.60s/it]
evaluating self.num_timesteps=79872, mean_reward=470.53436279296875=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.26s/it]
evaluating self.num_timesteps=80896, mean_reward=463.14947509765625=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:50<00:00,  2.51s/it]
evaluating self.num_timesteps=81920, mean_reward=457.92279052734375=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:54<00:00,  2.72s/it]
evaluating self.num_timesteps=82944, mean_reward=461.05780029296875=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:48<00:00,  2.43s/it]
evaluating self.num_timesteps=83968, mean_reward=477.5782775878906=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.26s/it]
evaluating self.num_timesteps=84992, mean_reward=447.7735900878906=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.32s/it]
evaluating self.num_timesteps=86016, mean_reward=436.7516174316406=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:47<00:00,  2.39s/it]
evaluating self.num_timesteps=87040, mean_reward=384.0249328613281=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:48<00:00,  2.45s/it]
evaluating self.num_timesteps=88064, mean_reward=417.65704345703125=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.33s/it]
evaluating self.num_timesteps=89088, mean_reward=423.52471923828125=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:49<00:00,  2.48s/it]
evaluating self.num_timesteps=90112, mean_reward=413.62921142578125=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:47<00:00,  2.40s/it]
evaluating self.num_timesteps=91136, mean_reward=342.8654479980469=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:47<00:00,  2.37s/it]
evaluating self.num_timesteps=92160, mean_reward=452.96337890625=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.32s/it]
evaluating self.num_timesteps=93184, mean_reward=417.2952575683594=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.28s/it]
evaluating self.num_timesteps=94208, mean_reward=388.72540283203125=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.27s/it]
evaluating self.num_timesteps=95232, mean_reward=394.0212707519531=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.26s/it]
evaluating self.num_timesteps=96256, mean_reward=396.2081604003906=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:46<00:00,  2.33s/it]
evaluating self.num_timesteps=97280, mean_reward=414.58953857421875=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.26s/it]
evaluating self.num_timesteps=98304, mean_reward=401.68023681640625=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.29s/it]
evaluating self.num_timesteps=99328, mean_reward=418.964111328125=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.28s/it]
evaluating self.num_timesteps=100352, mean_reward=462.8814392089844=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:45<00:00,  2.27s/it]
evaluating self.num_timesteps=101376, mean_reward=418.63201904296875=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.20s/it]
evaluating self.num_timesteps=102400, mean_reward=438.11859130859375=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 505.95770263671875
Evaluating model on hammer-v2...
 83%|████████████████████████████████████████████████████████████████████████████████▌                | 83/100 [03:07<00:44,  2.6 84%|█████████████████████████████████████████████████████████████████████████████████▍               | 84/100 [03:10<00:43,  2.7 85%|██████████████████████████████████████████████████████████████████████████████████▍              | 85/100 [03:12<00:40,  2.70s/it] 86%|███████████████████████████████████████████████████████████████████████████████████▍             | 86/100 [03:15<00:36,  2.60s 87%|████████████████████████████████████████████████████████████████████████████████████▍            | 87/100 [03:16<00:31,  2.39s 88%|█████████████████████████████████████████████████████████████████████████████████████▎           | 88/100 [03:18<0 89%|██████████████████████████████████████████████████████████████████████████████████████▎          | 89/100 [03:21<00:27,  2.5 90%|███████████████████████████████████████████████████████████████████████████████████████▎         | 90/100 [03:23<00:23,  2.3 91%|████████████████████████████████████████████████████████████████████████████████████████▎        | 91/100 [03:25<00:19,  2.1 92%|█████████████████████████████████████████████████████████████████████████████████████████▏       | 92/100 [03:27<00:16,  2.0 93%|██████████████████████████████████████████████████████████████████████████████████████████▏      | 93/100 [03:29<00:14,  2.0 94%|███████████████████████████████████████████████████████████████████████████████████████████▏     | 94/100 [03:31<00:12,  2.0 95%|███████████████████ 96%|█████████████████████████████████████████████████████████████████████████████████████████████    | 96/100 [03:36<00:08,  2.11s 97%|██████████████████████████████████████████████████████████████████████████████████████████████   | 97/100 [03:37<00:06,  2.06s 98%|███████████████████████████████████████████████████████████████████████████████████████████████  | 98/100 [03:39<00:03,  2.00s 99%|████████████████████████████████████████████████████████████████████████████████████████████████ | 99/100 [03:41<00:01,  1.98s100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:43<00:00,  1.94s100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:43<00:00,  2.24s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:59<00:00,  1.79s/it]
ppo+pnn Hammer - Success: 0.0, Reward: 437.1542053222656
Evaluating on previous task: Reach (After Hammer)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:09<00:00,  1.89s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:23<00:00,  2.03s/it]
ppo+pnn Reach (After Hammer) - Success: 0.0, Reward: 373.2563781738281
Evaluating on previous task: Pick Place (After Hammer)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:36<00:00,  2.17s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:31<00:00,  2.11s/it]
ppo+pnn Pick Place (After Hammer) - Success: 0.0, Reward: 2.827207326889038

Final evaluation file complete. All combinations have been run.
Results saved to plots/eval_results_2025-05-09_01-47-14.csv

==== Running mode: bc+ppo+pnn ====

2025-05-09 18:05:38.456142: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-09 18:05:40.770096: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.

===== Starting Evaluation Mode: bc+ppo+pnn =====
Training model...
Collecting expert data for behavior cloning...
  0%|                                                                                                   | 0/10024 [00:00<?, ?it/s]C:\Users\sterl\cs4756\final project\robot-learning-final\final\Metaworld\metaworld\policies\policy.py:49: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]
  warnings.warn(
100%|██████████████████████████████████████████████████████████████████████████████████████| 10024/10024 [00:23<00:00, 434.20it/s]
Training actor and critic networks via behavior cloning...
Epoch 1/150 | Actor Loss: 1.04482 | Critic Loss: 0.99908
Epoch 21/150 | Actor Loss: 0.46143 | Critic Loss: 0.92422
Epoch 41/150 | Actor Loss: 0.24288 | Critic Loss: 0.86854
Epoch 61/150 | Actor Loss: 0.13526 | Critic Loss: 0.83282
Epoch 81/150 | Actor Loss: 0.07793 | Critic Loss: 0.77433
Epoch 101/150 | Actor Loss: 0.04599 | Critic Loss: 0.68017
Epoch 121/150 | Actor Loss: 0.02671 | Critic Loss: 0.63771
Epoch 141/150 | Actor Loss: 0.01576 | Critic Loss: 0.62103
Epoch 150/150 | Actor Loss: 0.01236 | Critic Loss: 0.61311
Warm start complete.
Saved plot to plots/warm_start_rew_plot_2025-05-09_01-47-14-bc_ppo_pnn-reach-v2.png
Saved plot to plots/warm_start_suc_plot_2025-05-09_01-47-14-bc_ppo_pnn-reach-v2.png
Saving model after warm start...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:20<00:00,  1.40s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:52<00:00,  1.91it/s]
Warm Start 2025-05-09_01-47-14-bc_ppo_pnn-reach-v2 Total reward: 3183.91943359375
Warm Start 2025-05-09_01-47-14-bc_ppo_pnn-reach-v2 Success percentage: 0.67
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=1024, mean_reward=2495.574462890625=======
evaluating self.num_timesteps=1024, success=0.7=======
model saved on eval reward: 2495.574462890625
--------------------
C:\Users\sterl\AppData\Roaming\Python\Python39\site-packages\numpy\core\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\sterl\AppData\Roaming\Python\Python39\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=2048, mean_reward=2614.522216796875=======
evaluating self.num_timesteps=2048, success=1.0=======
model saved on eval reward: 2614.522216796875
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=3072, mean_reward=2612.64404296875=======
evaluating self.num_timesteps=3072, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.43s/it]
evaluating self.num_timesteps=4096, mean_reward=2475.579345703125=======
evaluating self.num_timesteps=4096, success=0.8=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=5120, mean_reward=2299.55029296875=======
evaluating self.num_timesteps=5120, success=0.5=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=6144, mean_reward=2386.7373046875=======
evaluating self.num_timesteps=6144, success=0.85=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=7168, mean_reward=2350.49169921875=======
evaluating self.num_timesteps=7168, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.43s/it]
evaluating self.num_timesteps=8192, mean_reward=2304.66748046875=======
evaluating self.num_timesteps=8192, success=0.65=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=9216, mean_reward=1939.434326171875=======
evaluating self.num_timesteps=9216, success=0.55=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.43s/it]
evaluating self.num_timesteps=10240, mean_reward=2393.53759765625=======
evaluating self.num_timesteps=10240, success=0.15=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=11264, mean_reward=1933.247802734375=======
evaluating self.num_timesteps=11264, success=0.55=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=12288, mean_reward=2187.70556640625=======
evaluating self.num_timesteps=12288, success=0.4=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=13312, mean_reward=1959.9625244140625=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=14336, mean_reward=2112.59814453125=======
evaluating self.num_timesteps=14336, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=15360, mean_reward=1672.4752197265625=======
evaluating self.num_timesteps=15360, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=16384, mean_reward=2052.331787109375=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=17408, mean_reward=1678.4228515625=======
evaluating self.num_timesteps=17408, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=18432, mean_reward=1368.0509033203125=======
evaluating self.num_timesteps=18432, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=19456, mean_reward=1552.333251953125=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=20480, mean_reward=1431.9537353515625=======
evaluating self.num_timesteps=20480, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=21504, mean_reward=1743.501953125=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=22528, mean_reward=1144.62353515625=======
evaluating self.num_timesteps=22528, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=23552, mean_reward=1112.3043212890625=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=24576, mean_reward=1004.2626953125=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=25600, mean_reward=1089.917236328125=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=26624, mean_reward=1040.627685546875=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=27648, mean_reward=1449.348388671875=======
evaluating self.num_timesteps=27648, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=28672, mean_reward=1686.2252197265625=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=29696, mean_reward=1540.0107421875=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=30720, mean_reward=1234.09423828125=======
evaluating self.num_timesteps=30720, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=31744, mean_reward=785.1707763671875=======
evaluating self.num_timesteps=31744, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=32768, mean_reward=751.2999267578125=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=33792, mean_reward=621.8226318359375=======
evaluating self.num_timesteps=33792, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=34816, mean_reward=715.2573852539062=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=35840, mean_reward=766.6485595703125=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=36864, mean_reward=949.5335083007812=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=37888, mean_reward=1390.145263671875=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=38912, mean_reward=1476.1246337890625=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.43s/it]
evaluating self.num_timesteps=39936, mean_reward=1770.267333984375=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=40960, mean_reward=1231.9310302734375=======
evaluating self.num_timesteps=40960, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=41984, mean_reward=1050.625732421875=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=43008, mean_reward=1431.3521728515625=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=44032, mean_reward=1009.7977294921875=======
evaluating self.num_timesteps=44032, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=45056, mean_reward=1100.668701171875=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=46080, mean_reward=1244.714599609375=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=47104, mean_reward=963.8616333007812=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=48128, mean_reward=983.6060791015625=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=49152, mean_reward=851.9078369140625=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=50176, mean_reward=1171.3338623046875=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=51200, mean_reward=965.6515502929688=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=52224, mean_reward=1438.7750244140625=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=53248, mean_reward=1112.8310546875=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=54272, mean_reward=1563.619384765625=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=55296, mean_reward=1391.03955078125=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=56320, mean_reward=889.1136474609375=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=57344, mean_reward=615.7741088867188=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=58368, mean_reward=694.8914794921875=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=59392, mean_reward=672.3451538085938=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=60416, mean_reward=627.0872192382812=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.43s/it]
evaluating self.num_timesteps=61440, mean_reward=488.1808166503906=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=62464, mean_reward=425.6573181152344=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=63488, mean_reward=429.8214416503906=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=64512, mean_reward=397.9675598144531=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=65536, mean_reward=403.9201354980469=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=66560, mean_reward=433.8583984375=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=67584, mean_reward=378.0669860839844=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.43s/it]
evaluating self.num_timesteps=68608, mean_reward=453.14080810546875=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=69632, mean_reward=310.00537109375=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=70656, mean_reward=328.5945129394531=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=71680, mean_reward=330.8492126464844=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=72704, mean_reward=341.2044677734375=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=73728, mean_reward=338.3888854980469=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=74752, mean_reward=292.1156005859375=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=75776, mean_reward=280.2957763671875=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=76800, mean_reward=255.4329833984375=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=77824, mean_reward=243.86947631835938=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=78848, mean_reward=238.5953826904297=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=79872, mean_reward=246.7191619873047=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=80896, mean_reward=258.4415283203125=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=81920, mean_reward=224.06527709960938=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=82944, mean_reward=219.9368896484375=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=83968, mean_reward=238.80831909179688=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=84992, mean_reward=265.4714660644531=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=86016, mean_reward=341.41693115234375=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=87040, mean_reward=324.54278564453125=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=88064, mean_reward=408.98541259765625=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=89088, mean_reward=346.52557373046875=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=90112, mean_reward=328.7337341308594=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=91136, mean_reward=324.0205993652344=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=92160, mean_reward=367.36822509765625=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.41s/it]
evaluating self.num_timesteps=93184, mean_reward=387.9786682128906=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=94208, mean_reward=280.6928405761719=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]
evaluating self.num_timesteps=95232, mean_reward=363.72100830078125=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=96256, mean_reward=341.97509765625=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]
evaluating self.num_timesteps=97280, mean_reward=419.0895080566406=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=98304, mean_reward=356.23651123046875=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.38s/it]
evaluating self.num_timesteps=99328, mean_reward=326.59149169921875=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.40s/it]
evaluating self.num_timesteps=100352, mean_reward=324.79766845703125=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=101376, mean_reward=366.1318359375=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.40s/it]
evaluating self.num_timesteps=102400, mean_reward=363.8194580078125=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 2614.522216796875
Evaluating model on reach-v2...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:20<00:00,  1.40s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:16<00:00,  1.37s/it]
bc+ppo+pnn Reach - Success: 0.0, Reward: 361.26324462890625
Training model...
Collecting expert data for behavior cloning...
100%|██████████████████████████████████████████████████████████████████████████████████████| 10024/10024 [00:25<00:00, 396.80it/s]
Training actor and critic networks via behavior cloning...
Epoch 1/250 | Actor Loss: 1.32651 | Critic Loss: 0.96548
Epoch 21/250 | Actor Loss: 0.51723 | Critic Loss: 0.49500
Epoch 41/250 | Actor Loss: 0.28938 | Critic Loss: 0.44375
Epoch 61/250 | Actor Loss: 0.16976 | Critic Loss: 0.42800
Epoch 81/250 | Actor Loss: 0.10151 | Critic Loss: 0.43556
Epoch 101/250 | Actor Loss: 0.06078 | Critic Loss: 0.40283
Epoch 121/250 | Actor Loss: 0.03858 | Critic Loss: 0.37182
Epoch 141/250 | Actor Loss: 0.02527 | Critic Loss: 0.37003
Epoch 161/250 | Actor Loss: 0.01662 | Critic Loss: 0.34664
Epoch 181/250 | Actor Loss: 0.01129 | Critic Loss: 0.33637
Epoch 201/250 | Actor Loss: 0.00835 | Critic Loss: 0.33806
Epoch 221/250 | Actor Loss: 0.00605 | Critic Loss: 0.33222
Epoch 241/250 | Actor Loss: 0.00533 | Critic Loss: 0.35370
Epoch 250/250 | Actor Loss: 0.00448 | Critic Loss: 0.32763
Warm start complete.
Saved plot to plots/warm_start_rew_plot_2025-05-09_01-47-14-bc_ppo_pnn-pick-place-v2.png
Saved plot to plots/warm_start_suc_plot_2025-05-09_01-47-14-bc_ppo_pnn-pick-place-v2.png
Saving model after warm start...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:59<00:00,  1.79s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.09it/s]
Warm Start 2025-05-09_01-47-14-bc_ppo_pnn-pick-place-v2 Total reward: 4.530986309051514
Warm Start 2025-05-09_01-47-14-bc_ppo_pnn-pick-place-v2 Success percentage: 0.91
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=1024, mean_reward=5.82039737701416=======
evaluating self.num_timesteps=1024, success=0.95=======
model saved on eval reward: 5.82039737701416
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=2048, mean_reward=38.94227981567383=======
evaluating self.num_timesteps=2048, success=0.0=======
model saved on eval reward: 38.94227981567383
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:37<00:00,  1.86s/it]
evaluating self.num_timesteps=3072, mean_reward=5.249320030212402=======
evaluating self.num_timesteps=3072, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:37<00:00,  1.87s/it]
evaluating self.num_timesteps=4096, mean_reward=5.3220720291137695=======
evaluating self.num_timesteps=4096, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=5120, mean_reward=4.959616661071777=======
evaluating self.num_timesteps=5120, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=6144, mean_reward=4.649839401245117=======
evaluating self.num_timesteps=6144, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=7168, mean_reward=6.293115615844727=======
evaluating self.num_timesteps=7168, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=8192, mean_reward=4.8422956466674805=======
evaluating self.num_timesteps=8192, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=9216, mean_reward=28.824726104736328=======
evaluating self.num_timesteps=9216, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=10240, mean_reward=18.247447967529297=======
evaluating self.num_timesteps=10240, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=11264, mean_reward=4.923190116882324=======
evaluating self.num_timesteps=11264, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=12288, mean_reward=8.03212833404541=======
evaluating self.num_timesteps=12288, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=13312, mean_reward=5.7660441398620605=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=14336, mean_reward=5.350551128387451=======
evaluating self.num_timesteps=14336, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=15360, mean_reward=34.4499397277832=======
evaluating self.num_timesteps=15360, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.78s/it]
evaluating self.num_timesteps=16384, mean_reward=4.464091777801514=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=17408, mean_reward=5.4260053634643555=======
evaluating self.num_timesteps=17408, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=18432, mean_reward=4.9033050537109375=======
evaluating self.num_timesteps=18432, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=19456, mean_reward=3.8014721870422363=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=20480, mean_reward=87.72266387939453=======
evaluating self.num_timesteps=20480, success=0.0=======
model saved on eval reward: 87.72266387939453
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=21504, mean_reward=4.016841411590576=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=22528, mean_reward=3.4296367168426514=======
evaluating self.num_timesteps=22528, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=23552, mean_reward=3.378920793533325=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=24576, mean_reward=4.348784923553467=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=25600, mean_reward=5.617673397064209=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=26624, mean_reward=5.348197937011719=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=27648, mean_reward=3.8659400939941406=======
evaluating self.num_timesteps=27648, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=28672, mean_reward=5.35934591293335=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.84s/it]
evaluating self.num_timesteps=29696, mean_reward=4.862156867980957=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=30720, mean_reward=4.010080814361572=======
evaluating self.num_timesteps=30720, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=31744, mean_reward=4.442383289337158=======
evaluating self.num_timesteps=31744, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=32768, mean_reward=3.921574354171753=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=33792, mean_reward=463.25653076171875=======
evaluating self.num_timesteps=33792, success=0.0=======
model saved on eval reward: 463.25653076171875
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=34816, mean_reward=32.570899963378906=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=35840, mean_reward=4.178056240081787=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=36864, mean_reward=4.443549633026123=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.96s/it]
evaluating self.num_timesteps=37888, mean_reward=4.1178107261657715=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.67s/it]
evaluating self.num_timesteps=38912, mean_reward=3.293459415435791=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:56<00:00,  2.81s/it]
evaluating self.num_timesteps=39936, mean_reward=4.823963642120361=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.52s/it]
evaluating self.num_timesteps=40960, mean_reward=3.5008456707000732=======
evaluating self.num_timesteps=40960, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.55s/it]
evaluating self.num_timesteps=41984, mean_reward=4.25945520401001=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:30<00:00,  1.52s/it]
evaluating self.num_timesteps=43008, mean_reward=3.8775227069854736=======
evaluating self.num_timesteps=43008, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.59s/it]
evaluating self.num_timesteps=44032, mean_reward=5.115736484527588=======
evaluating self.num_timesteps=44032, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=45056, mean_reward=2.630500555038452=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.79s/it]
evaluating self.num_timesteps=46080, mean_reward=2.398214817047119=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.81s/it]
evaluating self.num_timesteps=47104, mean_reward=2.2498536109924316=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.83s/it]
evaluating self.num_timesteps=48128, mean_reward=2.3986294269561768=======
evaluating self.num_timesteps=48128, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.94s/it]
evaluating self.num_timesteps=49152, mean_reward=2.7656519412994385=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:03<00:00,  3.20s/it]
evaluating self.num_timesteps=50176, mean_reward=2.665802478790283=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:58<00:00,  2.92s/it]
evaluating self.num_timesteps=51200, mean_reward=2.7299981117248535=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.96s/it]
evaluating self.num_timesteps=52224, mean_reward=2.2127394676208496=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.96s/it]
evaluating self.num_timesteps=53248, mean_reward=2.389195442199707=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:57<00:00,  2.86s/it]
evaluating self.num_timesteps=54272, mean_reward=2.4511725902557373=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:00<00:00,  3.03s/it]
evaluating self.num_timesteps=55296, mean_reward=2.873356342315674=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.96s/it]
evaluating self.num_timesteps=56320, mean_reward=3.4391238689422607=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:01<00:00,  3.06s/it]
evaluating self.num_timesteps=57344, mean_reward=3.968268871307373=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:58<00:00,  2.90s/it]
evaluating self.num_timesteps=58368, mean_reward=4.36963415145874=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.97s/it]
evaluating self.num_timesteps=59392, mean_reward=4.671777248382568=======
evaluating self.num_timesteps=59392, success=0.3=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:02<00:00,  3.11s/it]
evaluating self.num_timesteps=60416, mean_reward=3.612980365753174=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:01<00:00,  3.10s/it]
evaluating self.num_timesteps=61440, mean_reward=3.199627161026001=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.98s/it]
evaluating self.num_timesteps=62464, mean_reward=2.6868062019348145=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:05<00:00,  3.29s/it]
evaluating self.num_timesteps=63488, mean_reward=3.366257429122925=======
evaluating self.num_timesteps=63488, success=0.35=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:00<00:00,  3.04s/it]
evaluating self.num_timesteps=64512, mean_reward=3.283454418182373=======
evaluating self.num_timesteps=64512, success=0.3=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:03<00:00,  3.17s/it]
evaluating self.num_timesteps=65536, mean_reward=2.539327621459961=======
evaluating self.num_timesteps=65536, success=0.35=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.96s/it]
evaluating self.num_timesteps=66560, mean_reward=2.948117733001709=======
evaluating self.num_timesteps=66560, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:56<00:00,  2.84s/it]
evaluating self.num_timesteps=67584, mean_reward=3.0038182735443115=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:07<00:00,  3.38s/it]
evaluating self.num_timesteps=68608, mean_reward=2.0753846168518066=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:57<00:00,  2.88s/it]
evaluating self.num_timesteps=69632, mean_reward=2.0829522609710693=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=70656, mean_reward=2.1435959339141846=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.60s/it]
evaluating self.num_timesteps=71680, mean_reward=1.98310124874115=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:57<00:00,  2.89s/it]
evaluating self.num_timesteps=72704, mean_reward=2.0588784217834473=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:54<00:00,  2.72s/it]
evaluating self.num_timesteps=73728, mean_reward=2.07340669631958=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.96s/it]
evaluating self.num_timesteps=74752, mean_reward=1.920587182044983=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:53<00:00,  2.67s/it]
evaluating self.num_timesteps=75776, mean_reward=2.2313363552093506=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:57<00:00,  2.88s/it]
evaluating self.num_timesteps=76800, mean_reward=2.1235601902008057=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:01<00:00,  3.08s/it]
evaluating self.num_timesteps=77824, mean_reward=23.069896697998047=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:59<00:00,  2.98s/it]
evaluating self.num_timesteps=78848, mean_reward=23.66517448425293=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]
evaluating self.num_timesteps=79872, mean_reward=314.5196838378906=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:31<00:00,  1.58s/it]
evaluating self.num_timesteps=80896, mean_reward=80.21233367919922=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=81920, mean_reward=82.35807800292969=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=82944, mean_reward=25.14322280883789=======
evaluating self.num_timesteps=82944, success=0.35=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.80s/it]
evaluating self.num_timesteps=83968, mean_reward=49.979652404785156=======
evaluating self.num_timesteps=83968, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.02s/it]
evaluating self.num_timesteps=84992, mean_reward=51.84235763549805=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=86016, mean_reward=253.9885711669922=======
evaluating self.num_timesteps=86016, success=0.3=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:37<00:00,  1.87s/it]
evaluating self.num_timesteps=87040, mean_reward=254.83541870117188=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:41<00:00,  2.05s/it]
evaluating self.num_timesteps=88064, mean_reward=365.90655517578125=======
evaluating self.num_timesteps=88064, success=0.1=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.01s/it]
evaluating self.num_timesteps=89088, mean_reward=14.02568531036377=======
evaluating self.num_timesteps=89088, success=0.25=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:41<00:00,  2.10s/it]
evaluating self.num_timesteps=90112, mean_reward=248.41323852539062=======
evaluating self.num_timesteps=90112, success=0.2=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=91136, mean_reward=269.0929870605469=======
evaluating self.num_timesteps=91136, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.02s/it]
evaluating self.num_timesteps=92160, mean_reward=32.975223541259766=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.92s/it]
evaluating self.num_timesteps=93184, mean_reward=134.99009704589844=======
evaluating self.num_timesteps=93184, success=0.15=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.95s/it]
evaluating self.num_timesteps=94208, mean_reward=17.284069061279297=======
evaluating self.num_timesteps=94208, success=0.4=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:35<00:00,  1.80s/it]
evaluating self.num_timesteps=95232, mean_reward=236.2269744873047=======
evaluating self.num_timesteps=95232, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.95s/it]
evaluating self.num_timesteps=96256, mean_reward=9.027791023254395=======
evaluating self.num_timesteps=96256, success=0.25=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=97280, mean_reward=32.82463455200195=======
evaluating self.num_timesteps=97280, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:37<00:00,  1.86s/it]
evaluating self.num_timesteps=98304, mean_reward=31.494054794311523=======
evaluating self.num_timesteps=98304, success=0.1=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:39<00:00,  1.99s/it]
evaluating self.num_timesteps=99328, mean_reward=167.4443359375=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.91s/it]
evaluating self.num_timesteps=100352, mean_reward=13.583892822265625=======
evaluating self.num_timesteps=100352, success=0.1=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:40<00:00,  2.04s/it]
evaluating self.num_timesteps=101376, mean_reward=19.082292556762695=======
evaluating self.num_timesteps=101376, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:41<00:00,  2.09s/it]
evaluating self.num_timesteps=102400, mean_reward=30.936809539794922=======
evaluating self.num_timesteps=102400, success=0.1=======
--------------------
model saved on eval reward: 463.25653076171875
Evaluating model on pick-place-v2...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:15<00:00,  1.95s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:56<00:00,  1.77s/it]
bc+ppo+pnn Pick Place - Success: 0.07, Reward: 67.54065704345703
Evaluating on previous task: Reach (After Pick Place)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:12<00:00,  1.92s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:43<00:00,  1.64s/it]
bc+ppo+pnn Reach (After Pick Place) - Success: 0.18, Reward: 613.0269775390625
Training model...
Collecting expert data for behavior cloning...
100%|██████████████████████████████████████████████████████████████████████████████████████| 10024/10024 [00:16<00:00, 592.80it/s]
Training actor and critic networks via behavior cloning...
Epoch 1/350 | Actor Loss: 1.36008 | Critic Loss: 0.93334
Epoch 21/350 | Actor Loss: 0.51023 | Critic Loss: 0.61904
Epoch 41/350 | Actor Loss: 0.29071 | Critic Loss: 0.60400
Epoch 61/350 | Actor Loss: 0.17679 | Critic Loss: 0.58617
Epoch 81/350 | Actor Loss: 0.11170 | Critic Loss: 0.58358
Epoch 101/350 | Actor Loss: 0.07125 | Critic Loss: 0.58903
Epoch 121/350 | Actor Loss: 0.05011 | Critic Loss: 0.57092
Epoch 141/350 | Actor Loss: 0.03805 | Critic Loss: 0.56508
Epoch 161/350 | Actor Loss: 0.02999 | Critic Loss: 0.57219
Epoch 181/350 | Actor Loss: 0.02340 | Critic Loss: 0.57982
Epoch 201/350 | Actor Loss: 0.02035 | Critic Loss: 0.55688
Epoch 221/350 | Actor Loss: 0.01706 | Critic Loss: 0.56532
Epoch 241/350 | Actor Loss: 0.01667 | Critic Loss: 0.55690
Epoch 261/350 | Actor Loss: 0.01659 | Critic Loss: 0.57927
Epoch 281/350 | Actor Loss: 0.01612 | Critic Loss: 0.55339
Epoch 301/350 | Actor Loss: 0.01436 | Critic Loss: 0.55674
Epoch 321/350 | Actor Loss: 0.01436 | Critic Loss: 0.54800
Epoch 341/350 | Actor Loss: 0.01256 | Critic Loss: 0.54541
Epoch 350/350 | Actor Loss: 0.01322 | Critic Loss: 0.54988
Warm start complete.
Saved plot to plots/warm_start_rew_plot_2025-05-09_01-47-14-bc_ppo_pnn-hammer-v2.png
Saved plot to plots/warm_start_suc_plot_2025-05-09_01-47-14-bc_ppo_pnn-hammer-v2.png
Saving model after warm start...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [06:02<00:00,  3.63s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:36<00:00,  2.16s/it]
Warm Start 2025-05-09_01-47-14-bc_ppo_pnn-hammer-v2 Total reward: 499.5820007324219
Warm Start 2025-05-09_01-47-14-bc_ppo_pnn-hammer-v2 Success percentage: 0.42
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:10<00:00,  3.52s/it]
evaluating self.num_timesteps=1024, mean_reward=504.463134765625=======
evaluating self.num_timesteps=1024, success=0.35=======
model saved on eval reward: 504.463134765625
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.59s/it]
evaluating self.num_timesteps=2048, mean_reward=493.0601501464844=======
evaluating self.num_timesteps=2048, success=0.55=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:05<00:00,  3.29s/it]
evaluating self.num_timesteps=3072, mean_reward=499.82568359375=======
evaluating self.num_timesteps=3072, success=0.2=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:07<00:00,  3.37s/it]
evaluating self.num_timesteps=4096, mean_reward=496.0628967285156=======
evaluating self.num_timesteps=4096, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:12<00:00,  3.61s/it]
evaluating self.num_timesteps=5120, mean_reward=483.127685546875=======
evaluating self.num_timesteps=5120, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:18<00:00,  3.91s/it]
evaluating self.num_timesteps=6144, mean_reward=479.29290771484375=======
evaluating self.num_timesteps=6144, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:13<00:00,  3.65s/it]
evaluating self.num_timesteps=7168, mean_reward=465.7254333496094=======
evaluating self.num_timesteps=7168, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.60s/it]
evaluating self.num_timesteps=8192, mean_reward=474.58349609375=======
evaluating self.num_timesteps=8192, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:58<00:00,  2.94s/it]
evaluating self.num_timesteps=9216, mean_reward=503.5563049316406=======
evaluating self.num_timesteps=9216, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:11<00:00,  3.59s/it]
evaluating self.num_timesteps=10240, mean_reward=430.2417907714844=======
evaluating self.num_timesteps=10240, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.82s/it]
evaluating self.num_timesteps=11264, mean_reward=495.15045166015625=======
evaluating self.num_timesteps=11264, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.85s/it]
evaluating self.num_timesteps=12288, mean_reward=393.6459655761719=======
evaluating self.num_timesteps=12288, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.85s/it]
evaluating self.num_timesteps=13312, mean_reward=485.05328369140625=======
evaluating self.num_timesteps=13312, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:36<00:00,  1.85s/it]
evaluating self.num_timesteps=14336, mean_reward=511.4535217285156=======
evaluating self.num_timesteps=14336, success=0.0=======
model saved on eval reward: 511.4535217285156
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.20s/it]
evaluating self.num_timesteps=15360, mean_reward=487.137451171875=======
evaluating self.num_timesteps=15360, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=16384, mean_reward=486.63409423828125=======
evaluating self.num_timesteps=16384, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=17408, mean_reward=495.53857421875=======
evaluating self.num_timesteps=17408, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=18432, mean_reward=505.87408447265625=======
evaluating self.num_timesteps=18432, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=19456, mean_reward=484.860107421875=======
evaluating self.num_timesteps=19456, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=20480, mean_reward=487.19317626953125=======
evaluating self.num_timesteps=20480, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=21504, mean_reward=488.43463134765625=======
evaluating self.num_timesteps=21504, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.15s/it]
evaluating self.num_timesteps=22528, mean_reward=476.30743408203125=======
evaluating self.num_timesteps=22528, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=23552, mean_reward=483.5497131347656=======
evaluating self.num_timesteps=23552, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.24s/it]
evaluating self.num_timesteps=24576, mean_reward=489.6293029785156=======
evaluating self.num_timesteps=24576, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=25600, mean_reward=469.26263427734375=======
evaluating self.num_timesteps=25600, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=26624, mean_reward=496.70819091796875=======
evaluating self.num_timesteps=26624, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=27648, mean_reward=481.5039978027344=======
evaluating self.num_timesteps=27648, success=0.5=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=28672, mean_reward=484.76202392578125=======
evaluating self.num_timesteps=28672, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=29696, mean_reward=483.6866760253906=======
evaluating self.num_timesteps=29696, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=30720, mean_reward=476.90618896484375=======
evaluating self.num_timesteps=30720, success=0.25=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=31744, mean_reward=490.23291015625=======
evaluating self.num_timesteps=31744, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=32768, mean_reward=465.0143127441406=======
evaluating self.num_timesteps=32768, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=33792, mean_reward=486.24114990234375=======
evaluating self.num_timesteps=33792, success=0.15=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=34816, mean_reward=481.580810546875=======
evaluating self.num_timesteps=34816, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=35840, mean_reward=485.97015380859375=======
evaluating self.num_timesteps=35840, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=36864, mean_reward=483.7689514160156=======
evaluating self.num_timesteps=36864, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=37888, mean_reward=481.94830322265625=======
evaluating self.num_timesteps=37888, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=38912, mean_reward=490.41668701171875=======
evaluating self.num_timesteps=38912, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=39936, mean_reward=486.89373779296875=======
evaluating self.num_timesteps=39936, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]
evaluating self.num_timesteps=40960, mean_reward=484.6806640625=======
evaluating self.num_timesteps=40960, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=41984, mean_reward=492.99481201171875=======
evaluating self.num_timesteps=41984, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=43008, mean_reward=462.90667724609375=======
evaluating self.num_timesteps=43008, success=0.05=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=44032, mean_reward=495.5306701660156=======
evaluating self.num_timesteps=44032, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=45056, mean_reward=484.7579650878906=======
evaluating self.num_timesteps=45056, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=46080, mean_reward=481.44049072265625=======
evaluating self.num_timesteps=46080, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=47104, mean_reward=488.909423828125=======
evaluating self.num_timesteps=47104, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.20s/it]
evaluating self.num_timesteps=48128, mean_reward=513.0665283203125=======
evaluating self.num_timesteps=48128, success=0.0=======
model saved on eval reward: 513.0665283203125
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=49152, mean_reward=485.0379333496094=======
evaluating self.num_timesteps=49152, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=50176, mean_reward=486.2510681152344=======
evaluating self.num_timesteps=50176, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=51200, mean_reward=479.9810485839844=======
evaluating self.num_timesteps=51200, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=52224, mean_reward=494.690185546875=======
evaluating self.num_timesteps=52224, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=53248, mean_reward=490.368408203125=======
evaluating self.num_timesteps=53248, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=54272, mean_reward=479.48333740234375=======
evaluating self.num_timesteps=54272, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]
evaluating self.num_timesteps=55296, mean_reward=333.34918212890625=======
evaluating self.num_timesteps=55296, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=56320, mean_reward=330.6466979980469=======
evaluating self.num_timesteps=56320, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]
evaluating self.num_timesteps=57344, mean_reward=299.6261291503906=======
evaluating self.num_timesteps=57344, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=58368, mean_reward=72.70568084716797=======
evaluating self.num_timesteps=58368, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=59392, mean_reward=146.04403686523438=======
evaluating self.num_timesteps=59392, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.25s/it]
evaluating self.num_timesteps=60416, mean_reward=81.9632568359375=======
evaluating self.num_timesteps=60416, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.20s/it]
evaluating self.num_timesteps=61440, mean_reward=79.74864196777344=======
evaluating self.num_timesteps=61440, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]
evaluating self.num_timesteps=62464, mean_reward=153.36109924316406=======
evaluating self.num_timesteps=62464, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=63488, mean_reward=162.39389038085938=======
evaluating self.num_timesteps=63488, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=64512, mean_reward=102.801025390625=======
evaluating self.num_timesteps=64512, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=65536, mean_reward=328.90118408203125=======
evaluating self.num_timesteps=65536, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=66560, mean_reward=171.81027221679688=======
evaluating self.num_timesteps=66560, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=67584, mean_reward=146.4107666015625=======
evaluating self.num_timesteps=67584, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.23s/it]
evaluating self.num_timesteps=68608, mean_reward=171.36138916015625=======
evaluating self.num_timesteps=68608, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:47<00:00,  2.38s/it]
evaluating self.num_timesteps=69632, mean_reward=114.31478118896484=======
evaluating self.num_timesteps=69632, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=70656, mean_reward=223.8620147705078=======
evaluating self.num_timesteps=70656, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=71680, mean_reward=259.8954772949219=======
evaluating self.num_timesteps=71680, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=72704, mean_reward=220.45980834960938=======
evaluating self.num_timesteps=72704, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.15s/it]
evaluating self.num_timesteps=73728, mean_reward=377.20965576171875=======
evaluating self.num_timesteps=73728, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=74752, mean_reward=311.9737548828125=======
evaluating self.num_timesteps=74752, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=75776, mean_reward=217.70230102539062=======
evaluating self.num_timesteps=75776, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=76800, mean_reward=262.2787170410156=======
evaluating self.num_timesteps=76800, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=77824, mean_reward=280.71063232421875=======
evaluating self.num_timesteps=77824, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=78848, mean_reward=266.71148681640625=======
evaluating self.num_timesteps=78848, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=79872, mean_reward=304.1874084472656=======
evaluating self.num_timesteps=79872, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=80896, mean_reward=255.97250366210938=======
evaluating self.num_timesteps=80896, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=81920, mean_reward=250.88803100585938=======
evaluating self.num_timesteps=81920, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.17s/it]
evaluating self.num_timesteps=82944, mean_reward=354.70611572265625=======
evaluating self.num_timesteps=82944, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.22s/it]
evaluating self.num_timesteps=83968, mean_reward=185.50177001953125=======
evaluating self.num_timesteps=83968, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=84992, mean_reward=360.588134765625=======
evaluating self.num_timesteps=84992, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=86016, mean_reward=255.4739532470703=======
evaluating self.num_timesteps=86016, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=87040, mean_reward=244.0154571533203=======
evaluating self.num_timesteps=87040, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.15s/it]
evaluating self.num_timesteps=88064, mean_reward=277.24420166015625=======
evaluating self.num_timesteps=88064, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=89088, mean_reward=299.8067626953125=======
evaluating self.num_timesteps=89088, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.20s/it]
evaluating self.num_timesteps=90112, mean_reward=264.65545654296875=======
evaluating self.num_timesteps=90112, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=91136, mean_reward=347.4602355957031=======
evaluating self.num_timesteps=91136, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=92160, mean_reward=309.62890625=======
evaluating self.num_timesteps=92160, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.20s/it]
evaluating self.num_timesteps=93184, mean_reward=310.92730712890625=======
evaluating self.num_timesteps=93184, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=94208, mean_reward=252.5323944091797=======
evaluating self.num_timesteps=94208, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=95232, mean_reward=345.39697265625=======
evaluating self.num_timesteps=95232, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=96256, mean_reward=207.1688232421875=======
evaluating self.num_timesteps=96256, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=97280, mean_reward=263.4434814453125=======
evaluating self.num_timesteps=97280, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.18s/it]
evaluating self.num_timesteps=98304, mean_reward=314.35467529296875=======
evaluating self.num_timesteps=98304, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.20s/it]
evaluating self.num_timesteps=99328, mean_reward=263.4636535644531=======
evaluating self.num_timesteps=99328, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:44<00:00,  2.21s/it]
evaluating self.num_timesteps=100352, mean_reward=329.4086608886719=======
evaluating self.num_timesteps=100352, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.19s/it]
evaluating self.num_timesteps=101376, mean_reward=276.812744140625=======
evaluating self.num_timesteps=101376, success=0.0=======
--------------------
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:43<00:00,  2.16s/it]
evaluating self.num_timesteps=102400, mean_reward=309.44061279296875=======
evaluating self.num_timesteps=102400, success=0.0=======
--------------------
model saved on eval reward: 513.0665283203125
Evaluating model on hammer-v2...
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:40<00:00,  2.20s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:33<00:00,  2.14s/it]
bc+ppo+pnn Hammer - Success: 0.0, Reward: 323.6181945800781
Evaluating on previous task: Reach (After Hammer)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:31<00:00,  2.11s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:26<00:00,  2.06s/it]
bc+ppo+pnn Reach (After Hammer) - Success: 0.0, Reward: 244.7261199951172
Evaluating on previous task: Pick Place (After Hammer)
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:40<00:00,  2.21s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:36<00:00,  2.16s/it]
bc+ppo+pnn Pick Place (After Hammer) - Success: 0.0, Reward: 2.5384418964385986

Final evaluation file complete. All combinations have been run.
Results saved to plots/eval_results_2025-05-09_01-47-14.csv
2025-05-10 03:11:36.568012: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-10 03:11:39.918321: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Generating plots from existing CSV: plots/eval_results_2025-05-09_01-47-14.csv
C:\Users\sterl\cs4756\final project\robot-learning-final\final\final.py:63: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  transfer_df["ContextLabel"] = (